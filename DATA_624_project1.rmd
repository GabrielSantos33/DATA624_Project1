---
title: "DATA624 Project-1"
author: "Gabriel Santos"
date: "2023-03-25"
output:
  rmdformats::material:
  html_document:
    df_print: paged
    toc: yes
    toc_collapsed: yes
    toc_float: yes
  html_notebook: default
  pdf_document:
    extra_dependencies:
    - geometry
    - multicol
    - multirow
  word_document:
    toc: yes
    toc_depth: '5'
theme: lumen
number_sections: yes
toc_depth: 3
---


# Project - 1

This project consists of 3 parts - two required and one bonus and is worth 15% of your grade.

**Part A – ATM Forecast, ATM624Data.xlsx**

In part A, I want you to forecast how much cash is taken out of 4 different ATM machines for May 2010.  The data is given in a single file.  The variable 'Cash' is provided in hundreds of dollars, other than that it is straight forward.   I am being somewhat ambiguous on purpose to make this have a little more business feeling.  Explain and demonstrate your process, techniques used and not used, and your actual forecast.  I am giving you data via an excel file, please provide your written report on your findings, visuals, discussion and your R code via an RPubs link along with the actual.rmd file  Also please submit the forecast which you will put in an Excel readable file.

**Part B – Forecasting Power, ResidentialCustomerForecastLoad-624.xlsx**

Part B consists of a simple dataset of residential power usage for January 1998 until December 2013. Your assignment is to model these data and a monthly forecast for 2014.  The data is given in a single file.  The variable ‘KWH’ is power consumption in Kilowatt hours, the rest is straight forward. Add this to your existing files above. 

**Part C – BONUS, optional (part or all), Waterflow_Pipe1.xlsx and Waterflow_Pipe2.xlsx**

Part C consists of two data sets.  These are simple 2 columns sets, however they have different time stamps.  Your optional assignment is to time-base sequence the data and aggregate based on hour (example of what this looks like, follows).  Note for multiple recordings within an hour, take the mean.  Then to determine if the data is stationary and can it be forecast.  If so, provide a week forward forecast and present results via Rpubs and .rmd and the forecast in an Excel readable file.  

# Libraries

```{r, message=FALSE, warning=FALSE}
library(tidyverse)
library(ggplot2)
library(kableExtra)
library(gridExtra)
library(rio)
library(fpp2)
library(urca)
library(rio)
library(forecast)
library(lubridate)
library(dplyr)
```

# Part A – ATM Forecast

## Objetive

The goal of the project is to explore time series, decomposition, forecasting, data preprocessing, exponential smoothing, and ARIMA.


## Load Data

First, load the excel data, clean it by dropping the NA values, and rearrange it to a better format:

```{r, message=FALSE, warning=FALSE}
atm <- import("https://raw.githubusercontent.com/GabrielSantos33/DATA624_Project1/main/ATM624Data.xlsx", col_types = c("date", "text", "numeric"))
atm_daily <- atm %>% drop_na() %>% spread(ATM, Cash) 
atm_daily 
```

According to the data in the table, we can see that the withdrawals from 'ATM4' are greater than the withdrawals from the other ATMs. In addition, the 'ATM3', most of the withdrawals are zero.


Generating the summary statistics and the boxplot:

```{r, message=FALSE, warning=FALSE}
par(mfrow=c(4,1))
for (i in 2:5) {
  print(summary(atm_daily[i]))
}
```

```{r, message=FALSE, warning=FALSE}
par(mfrow=c(1,4))
for (i in 2:5){
    boxplot(atm_daily[i], 
            main = sprintf("%s", names(atm_daily)[i]),
                  col="lightblue", width = 2)
}
```

From the above boxplots we see that 'ATM1' has numerous outliers, 'ATM2' has none, 'ATM3' has 3 (for every non-zero observation), and 'ATM4' has 3 outliers, one of which is quite extreme. . The transformation of outliers will be important for forecasting.


## Timeseries

Now, let's convert the data into a time series.


```{r, message=FALSE, warning=FALSE}
atm_ts <- ts(atm_daily %>% select(-DATE))
autoplot(atm_ts) +
  ggtitle("Daily Cash Withdrawal", subtitle = "4 ATM machines") +
  xlab("Day") +
  ylab("Hundreds of Dollars ($100)")
```

As the spike from ATM4 in the first plot makes it hard to see the details in ATM1, ATM2, and ATM3, individual plots will be shown below.

To handle the data better, the extremely high outlier in ATM4 will be replaced by median for better forecasting.

```{r, message=FALSE, warning=FALSE}
atm[1394,3] <- 403.839
atm %>% drop_na() %>% ggplot(aes(x=DATE, y=Cash, col=ATM)) +
  geom_line(show.legend = FALSE) +
  facet_wrap(~ATM, ncol=1, scales="free_y") +
  labs(title="Daily Cash Withdrawal from 4 ATM Machines", subtitle = "May 2019 to April 2020") +
  xlab("Date") + ylab("Hundreds of Dollars ($100)")
```

From the graphs we can see that 'ATM1' and 'ATM2' show seasonality. We will apply the Box-Cox transformation.
In the case of 'ATM3' we do not have enough information for the prediction. We can assume that the 'ATM3' possibly began its operation at the end of April 2020.
For 'ATM4' we will replace the outlier with the median so it is better for forecasting.



## ARIMA Models

### ATM1

```{r, message=FALSE, warning=FALSE}
atm1 <- atm_daily[2]
atm1 <- ts(atm1, frequency=7)
atm2 <- atm_daily[3]
atm2 <- ts(atm2, frequency=7)
atm3 <- atm_daily[4]
atm3 <- ts(atm3, start=363)
atm3[which(atm3==0)] <- NA
atm4 <- atm_daily[5]
atm4[285,] <- 403.839
atm4 <- ts(atm4, frequency=7)
```

```{r, message=FALSE, warning=FALSE}
ggtsdisplay(atm1, main="Daily Cash Withdrawal in ATM1 (May 2019 - April 2020)")
ggseasonplot(atm1)
ggsubseriesplot(atm1)
```

```{r, message=FALSE, warning=FALSE}
atm1_bc <- BoxCox(atm1, lambda = BoxCox.lambda(atm1))
ggtsdisplay(atm1_bc, main="ATM1 with BoxCox Transformation")
```


ATM1 is clearly with seasonality, which is weekly seasonality. The ACF and PACF plots have significant lag7, lag14, and lag21. This is a non-stationary timeseries. 

After applying Box-Cox transformation, we still see the weekly seasonality in the timeseries. Differencing is needed.


```{r, message=FALSE, warning=FALSE}
ggtsdisplay(diff(atm1_bc, 7), points=FALSE)
atm1_bc %>% diff(.,7) %>% ur.kpss() %>% summary()
```

The timeseries now appears to be stationary. ARIMA(p,d,q)(P,D,Q)[m] model has p/P as order of the autoregressive part, d/D as degree of first differencing involved, q/Q as order of the moving average part, and m as number of observations.
The non-seasonal significant lag1 in ACF and PACF suggest non-seasonal p=q=1.

The seasonal spike at lag7 suggest seasonal AR(1) and/or MA(1) components. As ACF decays gradually, this suggests seasonal AR(0) and MA(1), P=0, Q=1. I will try ARIMA(1,0,1)(0,1,1).

```{r, message=FALSE, warning=FALSE}
atm1_arima <- Arima(atm1, order=c(1,0,1), seasonal=c(0,1,1), lambda = BoxCox.lambda(atm1))
summary(atm1_arima)
checkresiduals(atm1_arima)
```

Now, let's use auto.arima to find out which is the best Arima model:

```{r, message=FALSE, warning=FALSE}
atm1_auto <- auto.arima(atm1, approximation = FALSE, lambda=BoxCox.lambda(atm1))
summary(atm1_auto)
checkresiduals(atm1_auto)
```

The ARIMA model found by 'auto.arima' is ARIMA(0,0,2)(0,1,1)[7]. The ARIMA model I suggested is ARIMA(1,0,1)(0,1,1)[7].

According to the error measures and the residual plots, both models represents the data well with similar AIC values, similar error measures, and similar p-values. Both models can be applied, but the best Arima model is ARIMA(0,0,2)(0,1,1)[7], because it has a smaller AICc.



```{r, message=FALSE, warning=FALSE}
atm1_model <- Arima(atm1, order=c(0,0,2), seasonal=c(0,1,1), lambda = BoxCox.lambda(atm1))
```

### ATM2


```{r, message=FALSE, warning=FALSE}
ggtsdisplay(atm2, main="Daily Cash Withdrawal in ATM2 (May 2019 - April 2020)")
ggseasonplot(atm2)
ggsubseriesplot(atm2)
```

```{r, message=FALSE, warning=FALSE}
atm2_bc <- BoxCox(atm2, lambda = BoxCox.lambda(atm2))
ggtsdisplay(atm2_bc, main="ATM2 with BoxCox Transformation")
```

ATM2 is clearly with seasonality, which is weekly seasonality. The ACF and PACF plots have significant lag7, lag14, and lag21.Thus, this is a non-stationary timeseries. 

After applying Box-Cox transformation, we still see the weekly seasonality in the timeseries. Differencing is needed.

```{r, message=FALSE, warning=FALSE}
ggtsdisplay(diff(atm2_bc, 7), points=FALSE)
atm2_bc %>% diff(.,7) %>% ur.kpss() %>% summary()
```

The timeseries now appears to be stationary. One seasonal differencing was applied so D=1, while the non-seasonal part suggests d=0. The seasonal lags at ACF sudden drops while the ones in PACF gradually decrease, suggest AR(0) and MA(1), so P=0, Q=1. The non-differenced ACF and PACF plots have spikes at lag2 and lag5, suggest p=2 and q=2.
I will try ARIMA(2,0,2)(0,1,1)[7].

```{r, message=FALSE, warning=FALSE}
atm2_arima <- Arima(atm2, order=c(2,0,2), seasonal=c(0,1,1), lambda = BoxCox.lambda(atm2))
summary(atm2_arima)
```

```{r, message=FALSE, warning=FALSE}
checkresiduals(atm2_arima)
```

Now, let's use auto.arima to find out which is the best Arima model:

```{r, message=FALSE, warning=FALSE}
atm2_auto <- auto.arima(atm2, approximation = FALSE, lambda=BoxCox.lambda(atm2))
summary(atm2_auto)
```

```{r, message=FALSE, warning=FALSE}
checkresiduals(atm2_auto)
```

The ARIMA model found by 'auto.arima' is ARIMA(2,0,2)(0,1,1)[7].The ARIMA model I suggested is ARIMA(2,0,2)(0,1,1)[7].Both models are the same.According to the error measures and the residual plots, the model represents the data well with small p-value.  


```{r, message=FALSE, warning=FALSE}
atm2_model <- Arima(atm2, order=c(2,0,2), seasonal=c(0,1,1), lambda = BoxCox.lambda(atm2))
```


### ATM3

```{r, message=FALSE, warning=FALSE}
ggtsdisplay(atm3, main="Daily Cash Withdrawal in ATM3 (May 2019 - April 2020)")
```

There is not enough information to forecast in the time series. Because there are only 3 data points. We can assume that it is an ATM that began to work at the end of April. Therefore, I will use a simple mean forecast.


### ATM4

 
```{r, message=FALSE, warning=FALSE}
ggtsdisplay(atm4, main="Daily Cash Withdrawal in ATM4 (May 2019 - April 2020)")
ggseasonplot(atm4)
ggsubseriesplot(atm4)
```

```{r, message=FALSE, warning=FALSE}
atm4_bc <- BoxCox(atm4, lambda = BoxCox.lambda(atm4))
ggtsdisplay(atm4_bc, main="ATM4 with BoxCox Transformation")
```

ATM4 is clearly with seasonality, which is weekly seasonality. The ACF and PACF plots have significant lag7, lag14, and lag21. Thus, this is a non-stationary timeseries.

After applying Box-Cox transformation, we still see the weekly seasonality in the timeseries. Differencing is needed.

```{r, message=FALSE, warning=FALSE}
ggtsdisplay(diff(atm4_bc, 7), points=FALSE)
```
```{r, message=FALSE, warning=FALSE}
atm4_bc %>% diff() %>% ur.kpss() %>% summary()
```

The timeseries now appears to be stationary. One seasonal differencing was applied so D=1, while the non-seasonal part suggests d=0. The seasonal lags at ACF sudden drops while the ones in PACF gradually decrease, suggest AR(0) and MA(1), so P=0, Q=1.There one non-seasonal spike at lag3 in ACF and PACF plots suggest p=q=1.I will try ARIMA(1,0,1)(0,1,1)[7].


```{r, message=FALSE, warning=FALSE}
atm4_arima <- Arima(atm4, order=c(1,0,1), seasonal=c(0,1,1), lambda = BoxCox.lambda(atm4))
summary(atm4_arima)
```

```{r, message=FALSE, warning=FALSE}
checkresiduals(atm4_arima)
```

Now, let's use auto.arima to find out which is the best Arima model:

```{r, message=FALSE, warning=FALSE}
atm4_auto <- auto.arima(atm4, approximation = FALSE, lambda=BoxCox.lambda(atm4))
summary(atm4_auto)
```
```{r, message=FALSE, warning=FALSE}
checkresiduals(atm4_auto)
```

The ARIMA model found by 'auto.arima' is ARIMA(1,0,0)(2,0,0)[7]. The ARIMA model I suggested is ARIMA(1,0,1)(0,1,1)[7].The model I suggested has smaller AICc and RMSE.I think that the best model is the model that I suggested.

```{r, message=FALSE, warning=FALSE}
atm4_model <- Arima(atm4, order=c(1,0,1), seasonal=c(0,1,1), lambda = BoxCox.lambda(atm4))
```


## Forecast

```{r, message=FALSE, warning=FALSE}
atm1_f <- forecast(atm1_model, 31, level=95)
atm2_f <- forecast(atm2_model, 31, level=95)
atm3_f <- meanf(atm3, 31, level=95)
atm4_f <- forecast(atm4_model, 31, level=95)

gridExtra::grid.arrange(
  autoplot(atm1_f) +
    labs(title="ATM1: ARIMA(0,0,2)(0,1,1)[7]", x="Day", y="Hundreds of Dollars($100)"),
  autoplot(atm2_f) +
    labs(title="ATM2: ARIMA(2,0,2)(0,1,1)[7]", x="Day", y="Hundreds of Dollars($100)"),
  autoplot(atm3_f) +
    labs(title="ATM3: meanf", x="Day", y="Hundreds of Dollars($100)"),
  autoplot(atm4_f) +
    labs(title="ATM4: ARIMA(1,0,1)(0,1,1)[7]", x="Day", y="Hundreds of Dollars($100)"),
  top = grid::textGrob("Forecast on Cash Withdrawal for May 2020")
)

export <- rbind(atm1_f$mean, atm2_f$mean, atm3_f$mean, atm4_f$mean)
write.csv(export, "ATM_Forecast.csv")

data.frame(export) %>% cbind(ATM = c('ATM1', 'ATM2', 'ATM3', 'ATM4')) %>% 
                    select(ATM, everything())
```


Export the results Forecast of ATM1, ATM2, ATM3 and ATM4 en el file: 'ATM_Forecast.csv'

I think that the ATM1 and ATM2 forecasts seem correct, but in the case of ATM4, the generated forecast does not seem to follow the pattern of the data, I do not think the forecast is reliable, suddenly it is necessary to apply another type of model. 


# Part B – Forecasting Power

## Objetive

The goal of the project is to explore time series, decomposition, forecasting, data preprocessing, exponential smoothing, and ARIMA.

## Load Data

First, load the excel data into R and clean it by using function 'tsclean()' which can handle outliers and NA value.

```{r, message=FALSE, warning=FALSE}
kwh <- import("https://raw.githubusercontent.com/GabrielSantos33/DATA624_Project1/main/ResidentialCustomerForecastLoad-624.xlsx")
kwh_ts <- ts(kwh[,"KWH"], start=c(1998,1), frequency=12) %>% 
  tsclean()
kwh_ts
```

```{r, message=FALSE, warning=FALSE}
summary(kwh[,"KWH"]) #before
summary(kwh_ts)
```


## Timeseries

Now, let’s convert the data into a time series.


```{r, message=FALSE, warning=FALSE}
autoplot(kwh_ts) +
  ggtitle("Monthly Residential Power Usage", subtitle = "Jan 1998 to Dec 2013 (KWH)") +
  xlab("Month") +
  ylab("Kilowatt hours (KWH)")
ggseasonplot(kwh_ts)
ggsubseriesplot(kwh_ts)
```
Seasonality is found in this timeseries and appears to have a peak every 6 months. The seasonality may be annual due to the high power usage during winter and summer.

## ARIMA Model

We see annual seasonality. 

```{r, message=FALSE, warning=FALSE}
ggtsdisplay(kwh_ts, main="Monthly Residential Power Usage (Jan 1998 to Dec 2013) - (KWH)")
```

We apply the BoxCox Transformation:

```{r, message=FALSE, warning=FALSE}
kwh_bc <- BoxCox(kwh_ts, lambda = BoxCox.lambda(kwh_ts))
ggtsdisplay(kwh_bc, main="kwh_ts with BoxCox Transformation")
```
Tried Box-Cox transformation on the timeseries but no huge differences. Will work on differencing instead. 


```{r, message=FALSE, warning=FALSE}
ggtsdisplay(diff(kwh_ts,12), points=FALSE)
kwh_ts %>% diff(.,12) %>% ur.kpss() %>% summary()
```

After differencing once, the timeseries now appears to be stationary. ARIMA(p,d,q)(P,D,Q)[m] model has p/P as order of the autoregressive part, d/D as degree of first differencing involved, q/Q as order of the moving average part, and m as number of observations. The non-seasonal significant lag1 in ACF and PACF suggest non-seasonal p=q=1.

The seasonal spike at lag7 in ACF and lag7 & lag14 in PACF suggest seasonal AR(1) and MA(2) components. As ACF decays gradually, this suggests seasonal AR(1) and MA(2), P=0, Q=2.
I will try ARIMA(1,0,1)(0,1,2).

```{r, message=FALSE, warning=FALSE}
kwh_arima <- Arima(kwh_ts, order=c(1,0,1), seasonal=c(0,1,2), lambda = BoxCox.lambda(kwh_ts))
summary(kwh_arima)
checkresiduals(kwh_arima)
```

Now, let's use auto.arima to find out which is the best Arima model:

```{r, message=FALSE, warning=FALSE}
kwh_auto <- auto.arima(kwh_ts, approximation = FALSE, lambda=BoxCox.lambda(kwh_ts))
checkresiduals(kwh_auto)
summary(kwh_auto)
```

The ARIMA model found by 'auto.arima' is ARIMA(1,0,0)(0,1,1)[12]. The ARIMA model I suggested is ARIMA(1,0,1)(0,1,2)[12]. 
According to the error measures and the residual plots, both models represents the data well with similar AIC values, similar error measures, and similar p-values. Both models can be applied, but the best Arima model is ARIMA(1,0,0)(0,1,1)[12], because it has a smaller AICc.


## Forecast

```{r, message=FALSE, warning=FALSE}
kwh_model <- Arima(kwh_ts, order=c(1,0,0), seasonal=c(0,1,1), lambda = BoxCox.lambda(kwh_ts))
kwh_f <- forecast(kwh_model, h=12, level=95)
kwh_f
autoplot(kwh_f)

export <- kwh_f$mean
write.csv(export, "kwh_Forecast.csv")
```

We write the forecast data in the file: 'kwh_Forecast.csv'

I think the forecast generated is accurate. Our forecast captures the seasonality of what appears to be increased demand in the summer and winter while falling between the peaks and troughs of more recent years..


# Part C– BONUS, optional (part or all)

## Objetive

The goal of the project is to explore time series, decomposition, forecasting, data preprocessing, exponential smoothing, and ARIMA.

## Load Data

Load the excel data:

```{r, message=FALSE, warning=FALSE}
wfp1 <- import("https://raw.githubusercontent.com/GabrielSantos33/DATA624_Project1/main/Waterflow_Pipe1.xlsx", col_types = c("date", "numeric"))
wfp2 <- import("https://raw.githubusercontent.com/GabrielSantos33/DATA624_Project1/main/Waterflow_Pipe2.xlsx", col_types = c("date", "numeric"))
colnames(wfp1) <- c("DateTime", "WaterFlow") 
colnames(wfp2) <- c("DateTime", "WaterFlow") 
```


Match the hour with wfp2:

```{r, message=FALSE, warning=FALSE}
wfp1 <- wfp1 %>% mutate(Date = as.Date(DateTime), Time = hour(DateTime)+1) %>% 
                  group_by(Date, Time) %>%
                  summarise(Water=mean(WaterFlow)) %>%
                  ungroup() %>%
                  mutate(DateTime=ymd_h(paste(Date,Time))) %>%
                  select(DateTime,Water)
wfp1
```

```{r, message=FALSE, warning=FALSE}
wfp2 <- wfp2 %>% mutate(Date = as.Date(DateTime), Time = hour(DateTime)) %>%
                  group_by(Date, Time) %>%
                  summarise(Water=mean(WaterFlow)) %>%
                  ungroup() %>%
                  mutate(DateTime=ymd_h(paste(Date,Time))) %>%
                  select(DateTime, Water)
wfp2
```


## Timeseries

Combining the two waterflows into one:

```{r, message=FALSE, warning=FALSE}
water <- full_join(wfp1, wfp2, by="DateTime", suffix=c("_1", "_2")) %>%
  mutate(Water_1=ifelse(is.na(Water_1), 0, Water_1)) %>%
  mutate(Water_2=ifelse(is.na(Water_2), 0, Water_2)) %>%
  mutate(Water = Water_1 + Water_2) %>%
  select(DateTime, Water)
water
```


```{r, message=FALSE, warning=FALSE}
water_ts <- ts(water$Water, frequency=24)
ggseasonplot(water_ts) + theme(legend.title = element_blank())
ggsubseriesplot(water_ts)
```

We cannot see significant seasonality involved in 'water_ts' however there is a slightly decreasing trend.  It is a non-stationary timeseries. 

```{r, message=FALSE, warning=FALSE}
water_ts <- ts(water$Water, frequency=24)
ggtsdisplay(water_ts, main="Daily Waterflow")
```

## ARIMA Model

We apply BocCox transformation:

```{r, message=FALSE, warning=FALSE}
water_bc <- BoxCox(water_ts, lambda = BoxCox.lambda(water_ts))
ggtsdisplay(water_bc, main="Water_ts with BoxCox Transformation")
```

Trend differencing is needed.

```{r, message=FALSE, warning=FALSE}
ndiffs(water_ts)
nsdiffs(water_ts)
ggtsdisplay(diff(water_bc), points=FALSE, main="Differenced water_ts with BoxCox Transformation")
water_bc %>% diff() %>% ur.kpss() %>% summary()
```

The timeseries now appears to be stationary. One seasonal differencing was applied so D=0, while the non-seasonal part suggests d=1. There is one seasonal lags in ACF, suggest Q=1. There one non-seasonal spike at lag1 in ACF suggest q=1.I will try ARIMA(0,1,1)(0,0,1)[24].


```{r, message=FALSE, warning=FALSE}
water_arima <- Arima(water_ts, order=c(0,1,1), seasonal=c(0,0,1), lambda = BoxCox.lambda(water_ts))
summary(water_arima)
```
```{r, message=FALSE, warning=FALSE}
checkresiduals(water_arima)
```

Now, let's use auto.arima to find out which is the best Arima model:

```{r, message=FALSE, warning=FALSE}
water_auto <- auto.arima(water_ts, approximation = FALSE, lambda=BoxCox.lambda(water_ts))
summary(water_auto)
```

```{r, message=FALSE, warning=FALSE}
checkresiduals(water_auto)
```

The ARIMA model found by 'auto.arima' is ARIMA(0,1,1)(1,0,0)[24].The ARIMA model I suggested is ARIMA(0,1,1)(0,0,1)[24].Both models are similars to each other, on the statistics with only 0.01 difference on AICc. I will use the model generated by 'auto.arima', ARIMA(0,1,1)(1,0,0)[24].  

```{r, message=FALSE, warning=FALSE}
water_model <- Arima(water_ts, order=c(0,1,1), seasonal=c(1,0,0), lambda = BoxCox.lambda(water_ts))
```


## Forecast

I performed the forecast on a week on water use, 7 days, for 24 hours.

```{r, message=FALSE, warning=FALSE}
water_f <- forecast(water_model, h=7*24, level=95)
autoplot(water_f) +
  labs(title="Water Usage Forecast", subtitle = "ARIMA(0,1,1)(1,0,0)[24]", x="Day")

export <- water_f$mean
write.csv(export, "Waterflow_Forecast.csv")
df <- data.frame(water_f) %>% select(Point.Forecast)
rownames(df) <- NULL
df
```


Let's generate the forecast data in the file 'Waterflow_Forecast.csv'.

I think that the forecast generated, allowing us to see what the water flow will be is not reliable, because we can see that it does not follow the pattern of the data. I think it's because its large, the forecasts are closer to the mean.















